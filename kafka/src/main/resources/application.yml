spring:
  kafka:
    producer:
      # broker实例初始化地址，以ip:port数据对形式存在，并以逗号分隔
      # kafka会从这个初始化地址出发，自动发现完整的集群成员信息
      bootstrap-servers: 139.129.108.126:9092, 139.129.108.126:9093, 139.129.108.126:9094
      # 向broker端发送的任何消息的式都必须是字节数组
      # 键序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 值序列化方式
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 控制消息的持久化程度  消息会被发送到指定topic分区leader所在的broker上， producer会等待从该leader broker返回消息的写入结果
      # acks含义: 给producer发送响应前，leader broker必须确保已成功写入该消息的副本数
      # 0：无须任何副本成功写入  1:leader副本须成功写入  all/-1：所有副本须成功写入
      acks: -1
      # 消息发送失败时，重试的次数  默认是0不重试
      # 当设置enable.idempotence=false并且max.in.flight.requests.per.connection=1，此时启用重试，可能会改变消息的顺序
      # 原因：如果存在两个批次发送到单个分区，并且第一个批次失败并重试，但第二个批次成功，那么第二个批次中的消息可能会首先出现
      retries: 3
      # 缓存消息的缓冲区大小，单位字节 默认32MB
      # kafka异步架构：消息会先发往内存缓冲区，由另外的读线程从内存缓冲区中读取然后做真正的发送
      buffer-memory: 33554432
      # 消息是否压缩，默认none，即不压缩  其他选项：gzip、snappy、lz4、zstd
      compression-type: none
      # 当多个消息发送到同一个分区时，会将多条消息封装进一个batch中来减少与broker的交互，默认16Kb
      batch-size: 16384
      # 用于跟踪请求源，向broker发出请求时，会带上这个字符串
      client-id: "yiou_data_client_1"
      # 以下是追加的其他配置项，需要使用properties做前缀
      properties:
        # 控制消息发送延时行为，默认0，即消息立即发送
        # 稍延时一会，每次发送的消息数会增加，吞吐量也会上升
        linger.ms: 4
        # producer端单次请求能够发送的最大消息大小，默认1MB
        max:
          request:
            size: 1048576
        # 客户端等待请求的响应超时时间，默认30s
        # 如果在超时之前没有收到响应，客户端将在必要时重新发送请求
        request:
          timeout:
            ms: 30000
    consumer:
      bootstrap-servers: 139.129.108.126:9092, 139.129.108.126:9093, 139.129.108.126:9094
      # 键解序列化方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 值解序列化方式
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 消费者组ID, 需保证唯一
      group-id: "consumer_group_1"
      # 是否自动提交位移, 设置为true，则consumer在后台自动提交位移：否则，用户需要手动提交位移
      # 如果业务上需要较强的精确处理一次的需求，最好改成false，手动提交位移
      enable-auto-commit: false
      # 当设置enable-auto-commit=true时，消费者端自动提交位移的间隔时间  默认5s
      auto-commit-interval: 5000
      # 指定了没有初始位移信息或当前位移在集群中不存在时，kafka的应对策略
      # earliest：指定从最早的位移开始消费; latest：指定从最新处位移开始消费; none：指定如果未发现位移信息或位移越界，则抛出异常
      auto-offset-reset: earliest
      # 单次 poll 调用返回的最大消息数,默认500条
      # 这个参数不影响底层抓取行为，消费者会缓存抓取来的消息，然后按照配置的数目返回
      max-poll-records: 500
      # 消费者发往消费者组协调者心跳的间隔时间，默认3000ms
      # 这个参数必须比session.timeout.ms小，通常小于它的1/3
      heartbeat-interval:
      # consumer端单次获取数据的最大字节数,默认1
      # 当单次获取数据量<配置的该值时，consumer会等待积累到一定的数据后才会响应
      # 我们可以将最大字节数设置的大一些，虽然增加了延迟，但获取了较高的吞吐量
      fetch-min-size: 512
      # 当不满足fetch-min-size时，服务器在响应获取请求之前阻塞的最长时间  默认500ms
      fetch-max-wait: 500
      properties:
        # 客户端定期向代理发送心跳，以表明其活动状态, 超过这个时间会被踢出组，开始重平衡。默认45000ms
        session:
          timeout:
            ms: 45000
        # 使用消费者组管理时，两次poll()方法调用的最大延迟  默认300000ms,5分钟
        # 当超过这个时间间隔没有向服务端发送poll()请求，会认为该consumer崩溃了，就会发起一次重平衡，并将分区分配给其他consumer
        # 业务处理中，一般将这个时间设置为大于业务运行时间
        max:
          poll:
            interval:
              ms: 300000



